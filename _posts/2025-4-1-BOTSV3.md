---
title: Boss of the SOC version 3 Write-ups
date: 2025-6-7 00:00:00 + 0700
categories: [siem, blue-teaming, soc, ctf-challenge]
tags: [splunk, threat-hunting, log-analysis, write-ups]    
author: <author_id>   
description: Frothly Beer is moving their infrastructure to the cloud using a multi-cloud strategy. Let's help them detect suspicious activities while their business evolves significantly. 
# toc: false - uncomment to turn off Table of Contents which is use for display content in right-panel 
#comments: false # uncomment to turn on comment 
image: /assets/images/preview/botsv3.png
---
# Introduction

Hi Splunkers! Welcome back to my **Boss of the SOC (BOTS)** series on my blog.

If you haven’t read my previous [BOTSv1 Write-ups](https://phamthanhsang-cs.site/posts/BOTSV1/) and [BOTSv2 Write-ups](https://phamthanhsang-cs.site/posts/BOTSV2/) yet, I highly recommend checking them out first. They’ll give you a solid understanding of [Boss of the SOC – the Blue Team CTF Challenge created by Splunk](https://www.splunk.com/en_us/blog/security/what-you-need-to-know-about-boss-of-the-soc.html). I’d really appreciate it!


### About Boss of the SOC Version 3

**Boss of the SOC Version 3** is the latest publicly available BOTS CTF Challenge created by Splunk. In this version, we step into the shoes of **Alice Bluebird** - a quirky cybersecurity analyst to help organizations uncover the root causes of their digital chaos.

In the previous version (BOTSv2), we helped **Frothly**, a fictional craft beer company, detect hidden threats in their environment. From insiders using Tor to hide their activities, to external APTs attempting to exfiltrate intellectual property - it was intense.

Now, in BOTSv3, Frothly has grown rapidly and their traditional infrastructure can no longer keep up. As part of their technological evolution, they’ve migrated their environment to the cloud — utilizing both **AWS** and **Azure** for different business needs.

But as we know, for hackers, there’s nowhere to hide. As security analysts, it’s our job to help Frothly identify suspicious activity and trace the **root cause of digital chaos** in their expanded cloud infrastructure.

> **Fun Fact about my Boss of the SOC series:**  
> BOTSv3 was actually the **first version I completed**, even before versions 1 and 2!  
> It all started back in **April 2024**, with a Splunk instance running on a Linux VM inside my VirtualBox.  
> Revisiting this version now not only helps **refresh the knowledge** I’ve gained, but also sharpens the **analytical skills** I’ve developed since then.
{: .prompt-info }

# Environment Setup

- **Pre-requisites:**  
  Participating in **Boss of the SOC (BOTS)** is easier than ever thanks to its availability on various platforms:
  - [TryHackMe](https://tryhackme.com/)
  - [CyberDefenders](https://cyberdefenders.org/)

  Unfortunately, **Boss of the SOC v3** doesn’t appear on Splunk’s official website, but they have made the dataset [public on GitHub](https://github.com/splunk/botsv3) for anyone who wants to download it and give it a try.

  > *However, all walkthroughs in this guide are based on a **self-hosted setup**, including an approximation of what the CTF scoreboard looks like.*
  > *If you'd like to follow along or set up your own environment, check out this [detailed setup guide](https://phamthanhsang-cs.github.io/posts/BOTS-setup/) where we walk through everything step-by-step. Thanks!*

- **Dataset Information:**  
  Unlike BOTSv1 and BOTSv2, the third version only includes a **pre-indexed dataset** (~320MB), with a total of around **2 million events**.

  ![pic1](assets/images/botsv3/pic1.png)

# Walkthrough 
### Let's Splunking !
Same as both previous versions. before deep diving into answer BOTS questions, i would like to prepare some SPL searches to help us easier to hunting threats: 
- First is `|metadata index="botsv1" type=sourcetypes | stats values(sourcetype)`, the following SPL command helps me quickly identify the sourcetypes present in the dataset. This gives me a clear idea of the types of data we should focus on during investigation:
- The second one is `|metasearch index="botsv1" sourcetype=<specific_sourcetype> <keyword>`.
- The third one is `|fieldsummary` with [marcro](https://docs.splunk.com/Splexicon:Searchmacro) setup. My search will look like this:

```sql
| fieldsummary 
| fields field values value 
| rex field=values max_match=0 "\"value\":\"(?<value>[^\"]+)\""
| fields field value
```
*And i'd set this search with marcro named `spog` (single pane of glass), you will see why those searches helped me so much in this walkthrough.*

![pic2](assets/images/botsv3/pic2.png)
_WELCOME BACK TO MY BOSS OF THE SOC SERIES_

### Series 200

#### Question 1 (200): List out the IAM users that accessed an AWS service (successfully or unsuccessfully) in Frothly's AWS environment? Answer guidance: Comma separated without spaces, in alphabetical order. (Example: ajackson,mjones,tmiller)

> And like with the previous versions, I always recommend spending a little time to get a bird's-eye view of the `index` and its associated `sourcetypes` before jumping into the logs.  
> This will give you a better understanding of the data and where to begin your hunt.
>
> ```sql
> | metadata index=botsv3 type=sourcetypes 
> | stats values(sourcetype)
> ```
{: .prompt-info }


Before diving into the logs, it's important to understand a few foundational concepts and services in the world-leading cloud computing platform — **Amazon Web Services (AWS)**.

> I’m a big fan of F1 racing, and it’s fascinating that AWS is a key partner of the competition.  
> They provide a service called **F1® Insights**, transforming a traditional sport into a data-driven one. 

When discussing cloud computing, people often think of most common services like:

- **Compute** (e.g., EC2 for AWS, Azure Virtual Machines, OCI VMs for Oracle)
- **Storage** (e.g., AWS S3, Azure Blob Storage, Google Cloud Storage)
- **Serverless** (e.g., AWS Lambda, Azure Functions)

For this question, we're focusing on **Identity and Access Management (IAM)** - like **AWS IAM** or **Microsoft Entra ID** - to track which users accessed services.


**High-Level Overview of Relevant AWS Services:**

**Logging & Activity Tracking**
- **`aws:cloudtrail`**: Records API activity and management events.  
   *Primary service for auditing user activity (e.g., starting EC2 instances, creating S3 buckets).*

**Monitoring & Alerts**
- **`aws:cloudwatch`**: Monitors resources/applications, collects metrics, sets alarms, and builds dashboards.
- **`aws:cloudwatchlogs`**: Core log storage backend for services like EC2, Lambda, Route53.
- **`aws:cloudwatchlogs:vpcflow`**: Captures IP traffic to/from network interfaces in your **VPC** (Virtual Private Cloud).
- **`aws:cloudwatch:guardduty`**: Threat detection using ML to identify and alert on suspicious activity.

**Configuration & Compliance**
- **`aws:config:rule`**: Continuously checks resources against compliance rules (e.g., tagging, encryption, instance types).

**Storage & Access**
- **`aws:s3:accesslogs`**: Provides detailed records of requests to S3 buckets.

**Load Balancing**
- **`aws:elb:accesslogs`**: Tracks all traffic sent to Elastic Load Balancers (ELB).

**Relational Databases (RDS)**
- **`aws:rds:audit`**: Tracks database activities for engines like PostgreSQL, MySQL, Oracle.
- **`aws:rds:error`**: Logs engine errors for RDS services.

**Metadata**
- **`aws:description`**: Contains descriptive metadata about various AWS services (e.g., names, tags, IDs).

This understanding will help guide our log searches, especially focusing on **CloudTrail** and **CloudWatch** logs to identify IAM users and their interactions with AWS services.

The **CloudTrail** service records most user activity, and AWS provides detailed documentation about the fields used in these API tracking logs, which is extremely helpful.

[CloudTrail record contents for management, data, and network activity events](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-record-contents.html)

![pic3](assets/images/botsv3/pic3.png)

This information gives us a clear idea of where to begin when analyzing the logs.

```sql
index=botsv3 sourcetype=aws:cloudtrail AND eventType=AwsConsoleSignIn
```

Only 4 events were returned. Below is an example of one of these logs:

```json
{
  "requestParameters": null,
  "additionalEventData": {
    "MobileVersion": "No",
    "MFAUsed": "No",
    "LoginTo": "https://console.aws.amazon.com/console/home?state=hashArgs%23&isauthcode=true"
  },
  "eventTime": "2018-08-20T15:04:44Z",
  "eventID": "6ae589cc-9b68-4a08-a3c2-c29c9cd59b9b",
  "eventVersion": "1.05",
  "awsRegion": "us-east-1",
  "eventType": "AwsConsoleSignIn",
  "eventSource": "signin.amazonaws.com",
  "userIdentity": {
    "principalId": "AIDAJUFKXZ44LV4EN4MGK",
    "arn": "arn:aws:iam::622676721278:user/bstoll",
    "type": "IAMUser",
    "userName": "bstoll",
    "accountId": "622676721278"
  },
  "eventName": "ConsoleLogin",
  "recipientAccountId": "622676721278",
  "responseElements": {
    "ConsoleLogin": "Success"
  },
  "sourceIPAddress": "107.77.212.175",
  "userAgent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36"
}
```

The `userIdentity` field contains useful information we can extract to identify all IAM users active in Frothly’s AWS environment:

```sql
index=botsv3 sourcetype=aws:cloudtrail | spath "userIdentity.type" | search "userIdentity.type"=IAMUser| spath "userIdentity.userName" 
|table userIdentity.userName userIdentity.type
|stats count by userIdentity.userName userIdentity.type
|sort - userIdentity.userName
```

![pic4](assets/images/botsv3/pic4.png)

There were four users identified: `bstoll,btun,splunk_access,web_admin`.

> ANSWER: `bstoll,btun,splunk_access,web_admin`
{: .prompt-info }

#### Question 2 (201): What field would you use to alert that AWS API activity have occurred without MFA (multi-factor authentication)? Answer guidance: Provide the full JSON path. (Example: iceCream.flavors.traditional)

This question isn’t just about filling in the blank with the correct answer - it’s more about understanding how to **optimize** the approach and **choose the right fields** to make your detection logic effective. In this case, we’ll gradually narrow down events in CloudTrail to find a useful field for alerting.

The idea is to gather as many **relevant** logs as possible - the more targeted and consistent the field, the more effective and noise-free your alert will be.

I will filter only for `eventType=AwsApiCall` and then run a bird’s eye view using the `spog` macro (or similar approach) to audit the fields. We’re specifically looking for fields that:
- Appear in the logs.
- Have 3 or fewer unique values (easy to evaluate conditions).
- Are related to **MFA** (multi-factor authentication).

```sql
index=botsv3 sourcetype=aws:cloudtrail eventType=AwsApiCall
|search *mfa*
|fieldsummary
|fields field values
|rex field=values max_match=0 "\"value\":\"(?<value>[^\"]+)\""
|mvexpand value
|stats dc(value) as value_count values(value) as values by field
|where value_count <= 3
```

![pic5](assets/images/botsv3/pic5.png)
_The search results would look like thiThe search results above show various fields; we're looking for those relevant to MFA with few value variations_

Among the results, a promising field appeared: `userIdentity.sessionContext.attributes.mfaAuthenticated` - This field consistently reflects whether an AWS API activity was authenticated using MFA.

![pic6](assets/images/botsv3/pic6.png)

Upon deeper inspection, this field is populated in various eventName and eventSource combinations, making it ideal for a wide coverage alert that detects AWS API activity without MFA.

![pic7](assets/images/botsv3/pic7.png)

> ANSWER: `userIdentity.sessionContext.attributes.mfaAuthenticated`
{: .prompt-info }
